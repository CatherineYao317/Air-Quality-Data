{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98186069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "AQ_PATH = \"/Users/liyanwang/Desktop/2026winterProject/stat946/Air-Quality-Data-main/data/NeatData/AirQuality_ON_2022_2024.csv\"\n",
    "WX_PATH = \"/Users/liyanwang/Desktop/2026winterProject/stat946/Air-Quality-Data-main/data/NeatData/weather_ON_2022_2024.csv\"\n",
    "TR_PATH = \"/Users/liyanwang/Desktop/2026winterProject/stat946/Air-Quality-Data-main/data/NeatData/traffic_ON_2022_2024.csv\"\n",
    "\n",
    "OUT_MERGED = \"/Users/liyanwang/Desktop/2026winterProject/stat946/Air-Quality-Data-main/data/NeatData/merged_10km_daily_updated.csv\"\n",
    "OUT_REG_TXT = \"/Users/liyanwang/Desktop/2026winterProject/stat946/Air-Quality-Data-main/data/NeatData/regression_results_updated.txt\"\n",
    "\n",
    "START_DATE = \"2022-04-26\"\n",
    "END_DATE   = \"2024-09-26\"\n",
    "\n",
    "# Radius settings within 10km radius\n",
    "R_MIN_KM = 0\n",
    "R_MAX_KM = 10\n",
    "\n",
    "# Helper function\n",
    "def to_daily(x):\n",
    "    return pd.to_datetime(x, errors=\"coerce\").dt.normalize()\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Vectorized haversine distance (km).\n",
    "    lat1, lon1: (N,) arrays\n",
    "    lat2, lon2: (M,) arrays\n",
    "    return: (N, M) distance matrix in km\n",
    "    \"\"\"\n",
    "    R = 6371.0\n",
    "    lat1 = np.deg2rad(lat1)[:, None]\n",
    "    lon1 = np.deg2rad(lon1)[:, None]\n",
    "    lat2 = np.deg2rad(lat2)[None, :]\n",
    "    lon2 = np.deg2rad(lon2)[None, :]\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2.0)**2\n",
    "    c = 2*np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "def traffic_wide_to_long(tr_df):\n",
    "    \"\"\"\n",
    "    traffic is wide: xYYYY_MM_DD columns -> long (camera_id, date, traffic)\n",
    "    \"\"\"\n",
    "    date_cols = [c for c in tr_df.columns if re.fullmatch(r\"x\\d{4}_\\d{2}_\\d{2}\", str(c))]\n",
    "    id_cols = [c for c in tr_df.columns if c not in date_cols]\n",
    "    long_df = tr_df.melt(\n",
    "        id_vars=id_cols, value_vars=date_cols,\n",
    "        var_name=\"date_col\", value_name=\"traffic\"\n",
    "    )\n",
    "    long_df[\"date\"] = pd.to_datetime(\n",
    "        long_df[\"date_col\"].str[1:], format=\"%Y_%m_%d\", errors=\"coerce\"\n",
    "    ).dt.normalize()\n",
    "    long_df[\"traffic\"] = pd.to_numeric(long_df[\"traffic\"], errors=\"coerce\")\n",
    "    return long_df.drop(columns=[\"date_col\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3757fdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radius rule: 0–10 km\n",
      "AQ rows: 33535 Merged rows: 33535\n",
      "Saved: /Users/liyanwang/Desktop/2026winterProject/stat946/Air-Quality-Data-main/data/NeatData/merged_10km_daily_updated.csv\n",
      "Merged columns: ['Date', 'Station ID', 'Latitude', 'Longitude', 'CO_subAQI', 'NO2_subAQI', 'O3_subAQI', 'PM2.5_subAQI', 'SO2_subAQI', 'AQI', 'date', 'MeanTemp', 'TotalPrecip', 'MaxTemp', 'MinTemp', 'TotalRain', 'SnowOnGround', 'MaxGustSpd', 'wx_n', 'TempRange', 'TotalTraffic', 'tr_n']\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "aq = pd.read_csv(AQ_PATH, low_memory=False)\n",
    "wx = pd.read_csv(WX_PATH, low_memory=False)\n",
    "tr = pd.read_csv(TR_PATH, low_memory=False)\n",
    "\n",
    "# Standardize AQ (base table)\n",
    "# Date, Lat/Lon\n",
    "if \"Date\" in aq.columns:\n",
    "    aq[\"date\"] = to_daily(aq[\"Date\"])\n",
    "elif \"date\" in aq.columns:\n",
    "    aq[\"date\"] = to_daily(aq[\"date\"])\n",
    "else:\n",
    "    raise ValueError(\"AQ: cannot find date column ('Date' or 'date').\")\n",
    "AQ_LAT, AQ_LON = \"Latitude\", \"Longitude\"\n",
    "for c in [AQ_LAT, AQ_LON, \"Station ID\"]:\n",
    "    if c not in aq.columns:\n",
    "        raise ValueError(f\"AQ: missing column {c}\")\n",
    "# Filter date range\n",
    "aq = aq[aq[\"date\"].between(START_DATE, END_DATE)].copy()\n",
    "# Unique AQ stations for spatial matching\n",
    "aq_stations = (\n",
    "    aq[[\"Station ID\", AQ_LAT, AQ_LON]]\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "aq_stations[\"aq_sid\"] = aq_stations[\"Station ID\"].astype(str)\n",
    "\n",
    "# Weather: daily per weather station\n",
    "# Check weather date, lat/lon, temperature and precip\n",
    "if \"Date/Time\" in wx.columns:\n",
    "    wx[\"date\"] = to_daily(wx[\"Date/Time\"])\n",
    "elif \"date\" in wx.columns:\n",
    "    wx[\"date\"] = to_daily(wx[\"date\"])\n",
    "else:\n",
    "    raise ValueError(\"Weather: cannot find date column ('Date/Time' or 'date').\")\n",
    "\n",
    "WX_LAT, WX_LON = \"Latitude (y)\", '\"Longitude (x)\"'\n",
    "for c in [WX_LAT, WX_LON]:\n",
    "    if c not in wx.columns:\n",
    "        raise ValueError(f\"Weather: missing column {c}\")\n",
    "\n",
    "# Mean air temperature – affects chemical reaction rates\n",
    "WX_MEAN_TEMP_COL = \"Mean Temp (°C)\"\n",
    "# Max & Min temp used to compute diurnal temperature range, reflecting atmospheric stability and vertical dispersion\n",
    "WX_MAX_TEMP_COL  = \"Max Temp (°C)\"\n",
    "WX_MIN_TEMP_COL  = \"Min Temp (°C)\"\n",
    "# Total precip captures wet deposition that removes pollutants from air\n",
    "WX_TOTAL_PRECIP_COL = \"Total Precip (mm)\"\n",
    "# Total rainfall directly linked to pollutant washout than total precip (rain + snow)\n",
    "WX_TOTAL_RAIN_COL   = \"Total Rain (mm)\"\n",
    "# Snow on ground indicates persistent winter surface conditions, especially useful in Canada winter\n",
    "WX_SNOW_GROUND_COL  = \"Snow on Grnd (cm)\"\n",
    "# Maximum gust speed – proxy for atmospheric ventilation and pollutant dispersion\n",
    "WX_MAX_GUST_SPD_COL = \"Spd of Max Gust (km/h)\"\n",
    "WX_COLS = [\n",
    "    WX_MEAN_TEMP_COL,\n",
    "    WX_MAX_TEMP_COL,\n",
    "    WX_MIN_TEMP_COL,\n",
    "    WX_TOTAL_PRECIP_COL,\n",
    "    WX_TOTAL_RAIN_COL,\n",
    "    WX_SNOW_GROUND_COL,\n",
    "    WX_MAX_GUST_SPD_COL,\n",
    "]\n",
    "missing = [c for c in WX_COLS if c not in wx.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Weather: missing columns: {missing}\")\n",
    "# Filter date range\n",
    "wx = wx[wx[\"date\"].between(START_DATE, END_DATE)].copy()\n",
    "# Unique Weather stations for spatial matching\n",
    "wx_sites = (\n",
    "    wx[[\"Station ID\", WX_LAT, WX_LON]]\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "wx_sites[\"wx_sid\"] = wx_sites[\"Station ID\"].astype(str)\n",
    "# Keep daily weather table keyed by wx_sid + date with all predictors\n",
    "wx_daily = (\n",
    "    wx.merge(wx_sites[[\"Station ID\", \"wx_sid\"]], on=\"Station ID\", how=\"left\")[\n",
    "        [\"wx_sid\", \"date\"] + WX_COLS\n",
    "    ].copy()\n",
    ")\n",
    "for c in WX_COLS:\n",
    "    wx_daily[c] = pd.to_numeric(wx_daily[c], errors=\"coerce\")\n",
    "\n",
    "# Traffic: wide -> long (camera daily)\n",
    "# Convert wide to long\n",
    "if any(re.fullmatch(r\"x\\d{4}_\\d{2}_\\d{2}\", str(c)) for c in tr.columns):\n",
    "    tr_long = traffic_wide_to_long(tr)\n",
    "else:\n",
    "    tr_long = tr.copy()\n",
    "    if \"date\" in tr_long.columns:\n",
    "        tr_long[\"date\"] = to_daily(tr_long[\"date\"])\n",
    "    else:\n",
    "        raise ValueError(\"Traffic: cannot find xYYYY_MM_DD columns or 'date' column.\")\n",
    "# Filter date range\n",
    "tr_long = tr_long[tr_long[\"date\"].between(START_DATE, END_DATE)].copy()\n",
    "TR_LAT, TR_LON = \"latitude\", \"longitude\"\n",
    "for c in [TR_LAT, TR_LON]:\n",
    "    if c not in tr_long.columns:\n",
    "        raise ValueError(f\"Traffic: missing column {c}\")\n",
    "\n",
    "# define a traffic site id (camera id if exists; else lat/lon)\n",
    "if \"traffic_camera\" in tr_long.columns:\n",
    "    tr_long[\"tr_sid\"] = tr_long[\"traffic_camera\"].astype(str)\n",
    "else:\n",
    "    tr_long[\"tr_sid\"] = (tr_long[TR_LAT].astype(str) + \"_\" + tr_long[TR_LON].astype(str))\n",
    "tr_sites = (\n",
    "    tr_long[[\"tr_sid\", TR_LAT, TR_LON]]\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "tr_daily = tr_long[[\"tr_sid\", \"date\", \"traffic\"]].copy()\n",
    "\n",
    "\n",
    "# 7) Build spatial pairs (AQ station -> nearby WX/TR sites)\n",
    "# AQ -> Weather pairs\n",
    "aq_lat = pd.to_numeric(aq_stations[AQ_LAT], errors=\"coerce\").to_numpy()\n",
    "aq_lon = pd.to_numeric(aq_stations[AQ_LON], errors=\"coerce\").to_numpy()\n",
    "wx_lat = pd.to_numeric(wx_sites[WX_LAT], errors=\"coerce\").to_numpy()\n",
    "wx_lon = pd.to_numeric(wx_sites[WX_LON], errors=\"coerce\").to_numpy()\n",
    "d_aw = haversine_km(aq_lat, aq_lon, wx_lat, wx_lon)\n",
    "mask_aw = (d_aw >= R_MIN_KM) & (d_aw <= R_MAX_KM)\n",
    "i, j = np.where(mask_aw)\n",
    "aq_wx_pairs = pd.DataFrame({\n",
    "    \"aq_sid\": aq_stations.loc[i, \"aq_sid\"].to_numpy(),\n",
    "    \"wx_sid\": wx_sites.loc[j, \"wx_sid\"].to_numpy()\n",
    "}).drop_duplicates()\n",
    "\n",
    "# AQ -> Traffic pairs\n",
    "tr_lat = pd.to_numeric(tr_sites[TR_LAT], errors=\"coerce\").to_numpy()\n",
    "tr_lon = pd.to_numeric(tr_sites[TR_LON], errors=\"coerce\").to_numpy()\n",
    "d_at = haversine_km(aq_lat, aq_lon, tr_lat, tr_lon)\n",
    "mask_at = (d_at >= R_MIN_KM) & (d_at <= R_MAX_KM)\n",
    "i2, j2 = np.where(mask_at)\n",
    "aq_tr_pairs = pd.DataFrame({\n",
    "    \"aq_sid\": aq_stations.loc[i2, \"aq_sid\"].to_numpy(),\n",
    "    \"tr_sid\": tr_sites.loc[j2, \"tr_sid\"].to_numpy()\n",
    "}).drop_duplicates()\n",
    "\n",
    "# Aggregate WX/TR to AQ station-day\n",
    "# Weather aggregation to AQ station-day\n",
    "aq_wx_daily = (\n",
    "    aq_wx_pairs.merge(wx_daily, on=\"wx_sid\", how=\"left\")\n",
    "              .groupby([\"aq_sid\", \"date\"], as_index=False)\n",
    "              .agg(\n",
    "                  MeanTemp=(WX_MEAN_TEMP_COL, \"mean\"),\n",
    "                  TotalPrecip=(WX_TOTAL_PRECIP_COL, \"mean\"),\n",
    "                  MaxTemp=(WX_MAX_TEMP_COL, \"mean\"),\n",
    "                  MinTemp=(WX_MIN_TEMP_COL, \"mean\"),\n",
    "                  TotalRain=(WX_TOTAL_RAIN_COL, \"mean\"),\n",
    "                  SnowOnGround=(WX_SNOW_GROUND_COL, \"median\"),\n",
    "                  MaxGustSpd=(WX_MAX_GUST_SPD_COL, \"mean\"),\n",
    "                  wx_n=(\"wx_sid\", \"nunique\")\n",
    "              )\n",
    ")\n",
    "aq_wx_daily[\"TempRange\"] = aq_wx_daily[\"MaxTemp\"] - aq_wx_daily[\"MinTemp\"]\n",
    "\n",
    "# Traffic aggregation to AQ station-day\n",
    "aq_tr_daily = (\n",
    "    aq_tr_pairs.merge(tr_daily, on=\"tr_sid\", how=\"left\")\n",
    "              .groupby([\"aq_sid\", \"date\"], as_index=False)\n",
    "              .agg(\n",
    "                  TotalTraffic=(\"traffic\", \"sum\"),\n",
    "                  tr_n=(\"tr_sid\", \"nunique\")  # number of unique cameras used\n",
    "              )\n",
    ")\n",
    "\n",
    "# 9) Merge back to AQ base\n",
    "aq_base = aq.copy()\n",
    "aq_base[\"aq_sid\"] = aq_base[\"Station ID\"].astype(str)\n",
    "merged = (\n",
    "    aq_base.merge(aq_wx_daily, on=[\"aq_sid\", \"date\"], how=\"left\")\n",
    "           .merge(aq_tr_daily, on=[\"aq_sid\", \"date\"], how=\"left\")\n",
    ")\n",
    "merged = merged.drop(columns=[\"aq_sid\"])\n",
    "\n",
    "# Save\n",
    "merged.to_csv(OUT_MERGED, index=False)\n",
    "\n",
    "print(f\"Radius rule: {R_MIN_KM}–{R_MAX_KM} km\")\n",
    "print(\"AQ rows:\", aq.shape[0], \"Merged rows:\", merged.shape[0])\n",
    "print(\"Saved:\", OUT_MERGED)\n",
    "print(\"Merged columns:\", merged.columns.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
