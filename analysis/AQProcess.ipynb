{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a3d703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cb9962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Output file\n",
    "### Please CHANGE the file path to save it locally\n",
    "OUT_HOURLY_AQI = \"/Users/cy027/Desktop/Master Term 3/STAT 946/hourly_AQI_EPA.csv\"\n",
    "OUT_DAILY_AQI = \"/Users/cy027/Desktop/Master Term 3/STAT 946/daily_AQI_EPA.csv\"\n",
    "\n",
    "# Define AQI Breakpoints for each Pollutant\n",
    "AQI_BREAKPOINTS = {\n",
    "    \"O3\": [\n",
    "        (0.000, 0.054,   0,  50),\n",
    "        (0.055, 0.070,  51, 100),\n",
    "        (0.071, 0.085, 101, 150),\n",
    "        (0.086, 0.105, 151, 200),\n",
    "        (0.106, 0.200, 201, 300),\n",
    "        (0.201, 0.604, 301, 500),\n",
    "    ],\n",
    "    \"PM2.5\": [\n",
    "        (0.0,   9.0,    0,  50),\n",
    "        (9.1,  35.4,   51, 100),\n",
    "        (35.5, 55.4,  101, 150),\n",
    "        (55.5, 125.4, 151, 200),\n",
    "        (125.5,225.4, 201, 300),\n",
    "        (225.5,325.4, 301, 500),\n",
    "    ],\n",
    "    \"CO\": [\n",
    "        (0.0,  4.4,    0,  50),\n",
    "        (4.5,  9.4,   51, 100),\n",
    "        (9.5, 12.4,  101, 150),\n",
    "        (12.5,15.4,  151, 200),\n",
    "        (15.5,30.4,  201, 300),\n",
    "        (30.5,50.4,  301, 500),\n",
    "    ],\n",
    "    \"SO2\": [\n",
    "        (0,   35,    0,  50),\n",
    "        (36,  75,   51, 100),\n",
    "        (76,  185, 101, 150),\n",
    "        (186, 304, 151, 200),\n",
    "        (305, 604, 201, 300),\n",
    "        (605,1004, 301, 500),\n",
    "    ],\n",
    "    \"NO2\": [\n",
    "        (0,    53,    0,  50),\n",
    "        (54,   100,  51, 100),\n",
    "        (101,  360, 101, 150),\n",
    "        (361,  649, 151, 200),\n",
    "        (650, 1249, 201, 300),\n",
    "        (1250,2049, 301, 500),\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "def truncate_conc(pollutant: str, x: float) -> float:\n",
    "    \"\"\"\n",
    "    Standardize each pollutant under EPA rule\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    if pollutant == \"O3\":      # truncate to 3 decimals\n",
    "        return np.floor(x * 1000) / 1000\n",
    "    if pollutant == \"PM2.5\":   # truncate to 1 decimal\n",
    "        return np.floor(x * 10) / 10\n",
    "    if pollutant == \"CO\":      # truncate to 1 decimal\n",
    "        return np.floor(x * 10) / 10\n",
    "    if pollutant in (\"SO2\", \"NO2\"):  # truncate to integer\n",
    "        return np.floor(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def calc_sub_aqi(pollutant: str, conc: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute pollutant-specific AQI sub-index using linear interpolation\n",
    "    \"\"\"\n",
    "    if pd.isna(conc):\n",
    "        return np.nan\n",
    "\n",
    "    bps = AQI_BREAKPOINTS[pollutant]\n",
    "\n",
    "    # If concentration exceeds highest breakpoint, extrapolate using last range\n",
    "    if conc > bps[-1][1]:\n",
    "        C_lo, C_hi, I_lo, I_hi = bps[-1]\n",
    "        return (I_hi - I_lo) / (C_hi - C_lo) * (conc - C_lo) + I_lo\n",
    "\n",
    "    for C_lo, C_hi, I_lo, I_hi in bps:\n",
    "        if C_lo <= conc <= C_hi:\n",
    "            return (I_hi - I_lo) / (C_hi - C_lo) * (conc - C_lo) + I_lo\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def daily_metric_from_hourly(vals, pollutant):\n",
    "    \"\"\"\n",
    "    Compute EPA \"daily design concentration\" from hourly data\n",
    "    \"\"\"\n",
    "    s = pd.Series(vals, dtype=\"float64\")\n",
    "    valid_n = s.notna().sum()\n",
    "\n",
    "    if pollutant in (\"O3\", \"CO\"):   # 8-hour rolling max\n",
    "        return s.rolling(8, min_periods=6).mean().max()\n",
    "\n",
    "    if pollutant in (\"NO2\", \"SO2\"): # 1-hour max\n",
    "        return s.max()\n",
    "\n",
    "    if pollutant == \"PM2.5\":        # 24-hour mean\n",
    "        return s.mean()\n",
    "\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46acf818",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Hourly AQI Data Preprocessing ###############\n",
    "\n",
    "# Path to your folder that contains all the AQI datasets for every stationxpollutants\n",
    "folder_path = '/Users/cy027/Desktop/Master Term 3/STAT 946/Case Study 1/air_quality_csv'\n",
    "\n",
    "hourly_dataframes = []\n",
    "# Loop through all CSV files in the folder\n",
    "for file_path in glob.glob(os.path.join(folder_path, \"*.csv\")):\n",
    "    metadata = pd.read_csv(file_path, nrows=10, header=None)\n",
    "    station_name = metadata.iloc[0, 0]\n",
    "    station_id = metadata.iloc[1, 1].split('(')[-1].replace(')', '') # Extract \"12008\"\n",
    "    lat = metadata.iloc[3, 1]\n",
    "    lon = metadata.iloc[4, 1]\n",
    "    pollutant_type = metadata.iloc[7, 1].split('(')[-1].split(' ')[-1].replace(')', '')\n",
    "    map_to_epa = {\n",
    "    \"CO\": \"CO\",\n",
    "    \"O3\": \"O3\",\n",
    "    \"NO2\": \"NO2\",\n",
    "    \"SO2\": \"SO2\",\n",
    "    \"PM2.5\": \"PM2.5\",\n",
    "    \"PM25\": \"PM2.5\",\n",
    "    }\n",
    "    pollutant = map_to_epa.get(pollutant_type, None)\n",
    "    df = pd.read_csv(file_path, skiprows=10, index_col=False)\n",
    "    df = df[df['Date'].astype(str).str.contains(r'\\d{4}-\\d{2}-\\d{2}', na=False)].copy()\n",
    "    df = df[pd.to_datetime(df['Date']).between('2022-04-26', '2024-09-26')]\n",
    "    df.columns = df.columns.str.strip()\n",
    "    hourly_cols = [col for col in df.columns if col.startswith('H')]\n",
    "    df[hourly_cols] = df[hourly_cols].mask(df[hourly_cols].abs() >= 999)\n",
    "\n",
    "    if pollutant == \"O3\":\n",
    "        df[hourly_cols] = df[hourly_cols] / 1000.0\n",
    "        \n",
    "    hourly_df = df.melt(\n",
    "    id_vars=['Date'],\n",
    "    value_vars=hourly_cols,\n",
    "    var_name='Hour',\n",
    "    value_name='Concentration'\n",
    "    )\n",
    "\n",
    "    hourly_df['Hour'] = (\n",
    "        hourly_df['Hour']\n",
    "        .str.extract(r'(\\d+)')\n",
    "        .astype(int)\n",
    "        - 1\n",
    "    )\n",
    "\n",
    "    hourly_df['Station ID'] = station_id\n",
    "    hourly_df['Station Name'] = station_name\n",
    "    hourly_df['Latitude'] = lat\n",
    "    hourly_df['Longitude'] = lon\n",
    "    hourly_df['Pollutant'] = pollutant\n",
    "\n",
    "    hourly_dataframes.append(\n",
    "        hourly_df[\n",
    "            ['Date', 'Hour', 'Station ID', 'Station Name', 'Latitude', 'Longitude', 'Pollutant', 'Concentration']\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76f074ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_list_hourly = []\n",
    "\n",
    "for df in hourly_dataframes:\n",
    "    standardized_list_hourly.append(\n",
    "        df[\n",
    "            [\n",
    "                'Date',\n",
    "                'Hour',\n",
    "                'Station ID',\n",
    "                'Station Name',\n",
    "                'Latitude',\n",
    "                'Longitude',\n",
    "                'Pollutant',\n",
    "                'Concentration'\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Combine all hourly data\n",
    "big_df = pd.concat(standardized_list_hourly, ignore_index=True)\n",
    "\n",
    "# Pivot to wide hourly format\n",
    "final_hourly_df = big_df.pivot_table(\n",
    "    index=['Date', 'Hour', 'Station ID', 'Station Name','Latitude', 'Longitude'],\n",
    "    columns='Pollutant',\n",
    "    values='Concentration'\n",
    ").reset_index()\n",
    "\n",
    "final_hourly_df.columns.name = None\n",
    "\n",
    "# Add max AQI column\n",
    "pollutant_cols = ['CO', 'NO2', 'O3', 'PM2.5', 'SO2']\n",
    "\n",
    "final_hourly_df['Max_AQI'] = final_hourly_df[pollutant_cols].max(\n",
    "    axis=1,\n",
    "    skipna=True\n",
    ")\n",
    "\n",
    "# Add the pollutant name that matches the max AQI\n",
    "final_hourly_df['Max_AQI_Pollutant'] = final_hourly_df[pollutant_cols].idxmax(axis=1)\n",
    "\n",
    "# Add weekday/weekend column\n",
    "final_hourly_df['Datetime'] = (\n",
    "    pd.to_datetime(final_hourly_df['Date']) +\n",
    "    pd.to_timedelta(final_hourly_df['Hour'], unit='h')\n",
    ")\n",
    "final_hourly_df['Day_Type'] = np.where(\n",
    "    final_hourly_df['Datetime'].dt.weekday < 5,\n",
    "    'Weekday',\n",
    "    'Weekend'\n",
    ")\n",
    "\n",
    "# Add season column\n",
    "final_hourly_df['Date'] = pd.to_datetime(final_hourly_df['Date'])\n",
    "def get_season(date):\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "\n",
    "    if (month == 3 and day >= 1) or (4 <= month <= 5):\n",
    "        return 'Spring'\n",
    "    elif 6 <= month <= 9:\n",
    "        return 'Summer'\n",
    "    elif 10 <= month <= 11:\n",
    "        return 'Fall'\n",
    "    else:\n",
    "        return 'Winter'\n",
    "\n",
    "final_hourly_df['Season'] = final_hourly_df['Date'].apply(get_season)\n",
    "\n",
    "\n",
    "ordered_cols = (\n",
    "    ['Date', 'Hour', 'Station ID', 'Station Name']\n",
    "    + pollutant_cols\n",
    "    + ['Max_AQI','Max_AQI_Pollutant', 'Day_Type', 'Season']\n",
    ")\n",
    "\n",
    "final_hourly_df = final_hourly_df[ordered_cols]\n",
    "final_hourly_df.to_csv(OUT_HOURLY_AQI, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1de9b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Daily AQI Data Preprocessing ###############\n",
    "\n",
    "# Path to your folder that contains all the AQI datasets for every stationxpollutants\n",
    "folder_path = '/Users/cy027/Desktop/Master Term 3/STAT 946/Case Study 1/air_quality_csv'\n",
    "\n",
    "daily_dataframes = []\n",
    "# Loop through all CSV files in the folder\n",
    "for file_path in glob.glob(os.path.join(folder_path, \"*.csv\")):\n",
    "    metadata = pd.read_csv(file_path, nrows=10, header=None)\n",
    "    station_id = metadata.iloc[1, 1].split('(')[-1].replace(')', '') # Extract \"12008\"\n",
    "    lat = metadata.iloc[3, 1]\n",
    "    lon = metadata.iloc[4, 1]\n",
    "    pollutant_type = metadata.iloc[7, 1].split('(')[-1].split(' ')[-1].replace(')', '')\n",
    "    map_to_epa = {\n",
    "    \"CO\": \"CO\",\n",
    "    \"O3\": \"O3\",\n",
    "    \"NO2\": \"NO2\",\n",
    "    \"SO2\": \"SO2\",\n",
    "    \"PM2.5\": \"PM2.5\",\n",
    "    \"PM25\": \"PM2.5\",\n",
    "    }\n",
    "    pollutant = map_to_epa.get(pollutant_type, None)\n",
    "    df = pd.read_csv(file_path, skiprows=10, index_col=False)\n",
    "    df = df[df['Date'].astype(str).str.contains(r'\\d{4}-\\d{2}-\\d{2}', na=False)].copy()\n",
    "    df = df[pd.to_datetime(df['Date']).between('2022-04-26', '2024-09-26')]\n",
    "    df.columns = df.columns.str.strip()\n",
    "    hourly_cols = [col for col in df.columns if col.startswith('H')]\n",
    "    df[hourly_cols] = df[hourly_cols].mask(df[hourly_cols].abs() >= 999)\n",
    "\n",
    "    if pollutant == \"O3\":\n",
    "        df[hourly_cols] = df[hourly_cols] / 1000.0\n",
    "\n",
    "    daily_conc = df[hourly_cols].apply(lambda r: daily_metric_from_hourly(r.values, pollutant), axis=1)\n",
    "\n",
    "    # Special EPA rule for SO2: if 1-hr max >=305 ppb, use 24-hr average\n",
    "    if pollutant == \"SO2\":\n",
    "        max1 = df[hourly_cols].max(axis=1)\n",
    "        avg24 = df[hourly_cols].mean(axis=1)\n",
    "        daily_conc = np.where(max1 >= 305, avg24, max1)\n",
    "        daily_conc = pd.Series(daily_conc, index=df.index)\n",
    "\n",
    "    daily_conc_trunc = daily_conc.apply(lambda x: truncate_conc(pollutant, x))\n",
    "    sub_aqi = daily_conc_trunc.apply(lambda x: calc_sub_aqi(pollutant, x)).round()\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "            \"Station ID\": station_id,\n",
    "            \"Latitude\": lat,\n",
    "            \"Longitude\": lon,\n",
    "            \"Date\": df[\"Date\"],\n",
    "            f\"{pollutant}_subAQI\": sub_aqi\n",
    "        })\n",
    "        \n",
    "    daily_dataframes.append(temp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76dc6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_list_daily = []\n",
    "for df in daily_dataframes:\n",
    "    # Identify which column is the pollutant value (e.g., 'PM2.5', 'NO2', etc.)\n",
    "    # It's the one column that isn't Date, Station ID, Lat, or Long\n",
    "    core_cols = {'Date', 'Station ID', 'Latitude', 'Longitude'}\n",
    "    pollutant_col = list(set(df.columns) - core_cols)[0]\n",
    "    # Rename that column to 'Value' and add a 'Pollutant_Type' label\n",
    "    temp_df = df.copy()\n",
    "    temp_df['Value'] = temp_df[pollutant_col]\n",
    "    temp_df['Pollutant_Type'] = pollutant_col\n",
    "    standardized_list_daily.append(temp_df[['Date', 'Station ID', 'Latitude', 'Longitude', 'Pollutant_Type', 'Value']])\n",
    "\n",
    "big_df = pd.concat(standardized_list_daily, ignore_index=True)\n",
    "# index: columns that stay the same\n",
    "# columns: the pollutant names that will become new headers\n",
    "# values: the actual measurement\n",
    "final_df = big_df.pivot_table(\n",
    "    index=['Date', 'Station ID', 'Latitude', 'Longitude'],\n",
    "    columns='Pollutant_Type',\n",
    "    values='Value'\n",
    ").reset_index()\n",
    "final_df.columns.name = None\n",
    "\n",
    "subaqi_cols = [c for c in final_df.columns if c.endswith(\"_subAQI\")]\n",
    "final_df[\"AQI\"] = final_df[subaqi_cols].max(axis=1, skipna=True)\n",
    "\n",
    "final_df.to_csv(OUT_DAILY_AQI, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
